import os
from pathlib import Path

import cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow.keras import layers

print("=" * 60)
print(" –ü–†–û–°–¢–û–ô –ò–ò –î–õ–Ø –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Ø –õ–ò–¶")
print("=" * 60)

# ================== –ù–ê–°–¢–†–û–ô–ö–ò ==================
DATA_PATH = "data"
IMG_SIZE = (64, 64)          # (width, height)
BATCH_SIZE = 32
EPOCHS = 20
MODELS_DIR = "models"
RESULTS_DIR = "results"
# ===============================================


def create_test_data():
    """–°–æ–∑–¥–∞—ë—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç."""
    print(" –°–æ–∑–¥–∞—é —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ...")

    faces_dir = os.path.join(DATA_PATH, "faces")
    non_faces_dir = os.path.join(DATA_PATH, "non_faces")
    os.makedirs(faces_dir, exist_ok=True)
    os.makedirs(non_faces_dir, exist_ok=True)

    # –õ–∏—Ü–∞
    for i in range(100):
        img = np.zeros((IMG_SIZE[1], IMG_SIZE[0], 3), dtype=np.uint8)

        cv2.ellipse(
            img,
            (IMG_SIZE[0] // 2, IMG_SIZE[1] // 2),
            (IMG_SIZE[0] // 4, IMG_SIZE[1] // 3),
            0, 0, 360,
            (255, 200, 150),
            -1
        )

        cv2.circle(img, (IMG_SIZE[0] // 2 - 15, IMG_SIZE[1] // 2 - 10), 5, (0, 0, 0), -1)
        cv2.circle(img, (IMG_SIZE[0] // 2 + 15, IMG_SIZE[1] // 2 - 10), 5, (0, 0, 0), -1)
        cv2.ellipse(img, (IMG_SIZE[0] // 2, IMG_SIZE[1] // 2 + 15), (10, 5), 0, 0, 180, (0, 0, 0), 2)

        out_path = os.path.join(faces_dir, f"face_{i:03d}.jpg")
        cv2.imwrite(out_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))

    # –ù–µ-–ª–∏—Ü–∞
    for i in range(100):
        img = np.zeros((IMG_SIZE[1], IMG_SIZE[0], 3), dtype=np.uint8)
        shape = np.random.choice(["square", "triangle", "circle"])
        color = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))

        if shape == "square":
            cv2.rectangle(img, (10, 10), (IMG_SIZE[0] - 10, IMG_SIZE[1] - 10), color, -1)
        elif shape == "triangle":
            pts = np.array([
                [IMG_SIZE[0] // 2, 10],
                [10, IMG_SIZE[1] - 10],
                [IMG_SIZE[0] - 10, IMG_SIZE[1] - 10]
            ])
            cv2.fillPoly(img, [pts], color)
        else:
            cv2.circle(img, (IMG_SIZE[0] // 2, IMG_SIZE[1] // 2), IMG_SIZE[0] // 3, color, -1)

        out_path = os.path.join(non_faces_dir, f"nonface_{i:03d}.jpg")
        cv2.imwrite(out_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))

    print(" –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–∑–¥–∞–Ω—ã!")


def load_and_prepare_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ data/faces –∏ data/non_faces, –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç, –¥–µ–ª–∏—Ç –Ω–∞ train/test."""
    print(" –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

    faces_dir = os.path.join(DATA_PATH, "faces")
    non_faces_dir = os.path.join(DATA_PATH, "non_faces")

    if not os.path.exists(faces_dir) or not os.path.exists(non_faces_dir):
        print(" –ü–∞–ø–∫–∏ —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –°–æ–∑–¥–∞—é —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ...")
        create_test_data()
    images = []
    labels = []

    face_files = list(Path(faces_dir).glob("*.jpg")) + list(Path(faces_dir).glob("*.png"))
    non_face_files = list(Path(non_faces_dir).glob("*.jpg")) + list(Path(non_faces_dir).glob("*.png"))

    print(f"üë§ –õ–∏—Ü: {len(face_files)} |  –ù–µ-–ª–∏—Ü: {len(non_face_files)}")

    # –õ–∏—Ü–∞ -> 1
    for img_path in face_files:
        img = cv2.imread(str(img_path))
        if img is None:
            continue
        img = cv2.resize(img, IMG_SIZE)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        images.append(img)
        labels.append(1)

# –ù–µ-–ª–∏—Ü–∞ -> 0
    for img_path in non_face_files:
        img = cv2.imread(str(img_path))
        if img is None:
            continue
        img = cv2.resize(img, IMG_SIZE)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        images.append(img)
        labels.append(0)

    if len(images) == 0:
        print(" –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
        return None, None, None, None

    X = np.array(images, dtype="float32") / 255.0
    y = np.array(labels, dtype="float32")

    if len(np.unique(y)) < 2:
        print(" –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è 2 –∫–ª–∞—Å—Å–æ–≤.")
        return None, None, None, None

    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=0.2,
        random_state=42,
        stratify=y
    )

    print(f" Train: {len(X_train)} |  Test: {len(X_test)}")
    return X_train, X_test, y_train, y_test


def create_model(input_shape):
    """–°–æ–∑–¥–∞—ë—Ç CNN –º–æ–¥–µ–ª—å."""
    print("\n –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")

    model = tf.keras.Sequential([
        layers.Input(shape=input_shape),

        layers.Conv2D(32, (3, 3), activation="relu", padding="same"),
        layers.MaxPooling2D((2, 2)),

        layers.Conv2D(64, (3, 3), activation="relu", padding="same"),
        layers.MaxPooling2D((2, 2)),

        layers.Flatten(),
        layers.Dense(128, activation="relu"),
        layers.Dropout(0.5),
        layers.Dense(64, activation="relu"),
        layers.Dense(1, activation="sigmoid")
    ])

    model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])
    model.summary()
    return model


def train_model(model, X_train, y_train, X_test, y_test):
    """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª—É—á—à—É—é."""
    print("\n –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...")

    os.makedirs(MODELS_DIR, exist_ok=True)

    checkpoint = tf.keras.callbacks.ModelCheckpoint(
        filepath=os.path.join(MODELS_DIR, "best_face_model.keras"),
        monitor="val_accuracy",
        save_best_only=True,
        mode="max",
        verbose=1
    )

    early_stop = tf.keras.callbacks.EarlyStopping(
        monitor="val_loss",
        patience=5,
        restore_best_weights=True
    )

    history = model.fit(
        X_train, y_train,
        validation_data=(X_test, y_test),
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        callbacks=[checkpoint, early_stop],
        verbose=1
    )

    return history, model


def evaluate_model(model, X_test, y_test):
    """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ —Ç–µ—Å—Ç–µ."""
    print("\n –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏...")
    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
    print(f" –¢–æ—á–Ω–æ—Å—Ç—å: {test_acc * 100:.2f}% | loss: {test_loss:.4f}")
    return test_acc


def plot_training_history(history):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≥—Ä–∞—Ñ–∏–∫–∏ accuracy/loss –≤ results/."""
    os.makedirs(RESULTS_DIR, exist_ok=True)

    # Accuracy
    plt.figure(figsize=(8, 4))
    plt.plot(history.history["accuracy"], label="accuracy")
    plt.plot(history.history["val_accuracy"], label="val_accuracy")
    plt.title("–¢–æ—á–Ω–æ—Å—Ç—å")
    plt.xlabel("–≠–ø–æ—Ö–∞")
    plt.ylabel("Accuracy")
    plt.grid(True)
    plt.legend()
    acc_path = os.path.join(RESULTS_DIR, "accuracy.png")
    plt.tight_layout()
    plt.savefig(acc_path, dpi=120)
    plt.show()
    print(f" –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {acc_path}")

    # Loss
    plt.figure(figsize=(8, 4))
    plt.plot(history.history["loss"], label="loss")
    plt.plot(history.history["val_loss"], label="val_loss")
    plt.title("–ü–æ—Ç–µ—Ä–∏")
    plt.xlabel("–≠–ø–æ—Ö–∞")
    plt.ylabel("Loss")
    plt.grid(True)
    plt.legend()
    loss_path = os.path.join(RESULTS_DIR, "loss.png")
    plt.tight_layout()
    plt.savefig(loss_path, dpi=120)
    plt.show()
    print(f" –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {loss_path}")


def test_on_single_image(model, image_path):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –æ–¥–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–∫–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞."""
    if not os.path.exists(image_path):
        print(f" –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {image_path}")
        return None

    img = cv2.imread(image_path)
    if img is None:
        print(" –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
        return None

    original = img.copy()

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    img_resized = cv2.resize(img, IMG_SIZE)
    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
    img_norm = img_rgb.astype("float32") / 255.0
    x = np.expand_dims(img_norm, axis=0)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    pred = float(model.predict(x, verbose=0)[0][0])

    # –¢–µ–∫—Å—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    if pred > 0.5:
        text = f"–õ–ò–¶–û ({pred * 100:.1f}%)"
        color = (0, 255, 0)
    else:
        text = f"–ù–ï –õ–ò–¶–û ({(1 - pred) * 100:.1f}%)"
        color = (0, 0, 255)

    # –ü–æ–∫–∞–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    cv2.putText(original, text, (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

    h, w = original.shape[:2]
    scale = 700 / max(h, w)
    resized = cv2.resize(original, (int(w * scale), int(h * scale)))

    cv2.imshow("–†–µ–∑—É–ª—å—Ç–∞—Ç", resized)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

    return pred

def main():
    X_train, X_test, y_train, y_test = load_and_prepare_data()
    if X_train is None:
        return

    model = create_model((IMG_SIZE[1], IMG_SIZE[0], 3))

    history, trained_model = train_model(model, X_train, y_train, X_test, y_test)
    evaluate_model(trained_model, X_test, y_test)
    plot_training_history(history)

    os.makedirs(MODELS_DIR, exist_ok=True)
    final_path = os.path.join(MODELS_DIR, "face_recognition_model.keras")
    trained_model.save(final_path)
    print(f"\n –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {final_path}")

    while True:
        print("\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:")
        print("1) –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–≤–æ—ë –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
        print("2) –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–ª—É—á–∞–π–Ω–æ–µ —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
        print("3) –í—ã–π—Ç–∏")

        choice = input("–í–≤–µ–¥–∏—Ç–µ 1-3: ").strip()

        if choice == "1":
            img_path = input(r"–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É (–ø—Ä–∏–º–µ—Ä: C:\Users\admin\Pictures\Camera Roll\photo.jpg): ").strip()
            test_on_single_image(trained_model, img_path)

        elif choice == "2":
            idx = np.random.randint(0, len(X_test))
            temp_img = (X_test[idx] * 255).astype("uint8")

            os.makedirs(RESULTS_DIR, exist_ok=True)
            temp_path = os.path.join(RESULTS_DIR, "temp_test.jpg")
            cv2.imwrite(temp_path, cv2.cvtColor(temp_img, cv2.COLOR_RGB2BGR))

            print(" –°–ª—É—á–∞–π–Ω—ã–π —Ç–µ—Å—Ç...")
            test_on_single_image(trained_model, temp_path)

            if os.path.exists(temp_path):
                os.remove(temp_path)

        elif choice == "3":
            print(" –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            break

        else:
            print(" –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä.")

if __name__ ==   "__main__":
    main()